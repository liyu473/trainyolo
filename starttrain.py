#!/usr/bin/env python3
"""
YOLOè®­ç»ƒä¸€ä½“åŒ–è„šæœ¬ - StartTrain.py
åŠŸèƒ½é›†æˆ:
1. GPU/CPUæ£€æµ‹å’Œé€‰æ‹©
2. æ•°æ®é›†å‡†å¤‡å’Œæ ¼å¼è½¬æ¢
3. YOLOæ¨¡å‹è®­ç»ƒ
4. æ¨¡å‹å¯¼å‡ºåˆ°Modelæ–‡ä»¶å¤¹
5. å¯é€‰ONNXæ ¼å¼è½¬æ¢

ä½œè€…: AI Assistant
"""

import os
import sys
import argparse
import shutil
import random
import platform
from datetime import datetime
from pathlib import Path

# æ£€æŸ¥ä¾èµ–
try:
    import torch
    from ultralytics import YOLO
    import yaml
except ImportError as e:
    print(f"é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…: {e}")
    print("è¯·è¿è¡Œ: pip install torch ultralytics pyyaml")
    sys.exit(1)


class YOLOTrainer:
    """YOLOè®­ç»ƒå™¨ç±»ï¼Œæ•´åˆæ‰€æœ‰è®­ç»ƒåŠŸèƒ½"""
    
    def __init__(self, args):
        self.args = args
        self.device = None
        self.model_output_dir = None
        
    def check_gpu(self):
        """æ£€æµ‹GPUå¯ç”¨æ€§å¹¶è®¾ç½®è®¾å¤‡"""
        print("=" * 50)
        print("ğŸ” æ£€æµ‹è®¡ç®—è®¾å¤‡...")
        print("=" * 50)
        
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"ç³»ç»Ÿ: {platform.system()} {platform.release()}")
        
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            print(f"âœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU:")
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                print(f"   GPU {i}: {gpu_name}")
            
            if self.args.force_cpu:
                print("âš ï¸  å¼ºåˆ¶ä½¿ç”¨CPUæ¨¡å¼")
                self.device = 'cpu'
            else:
                self.device = '0' if gpu_count == 1 else ','.join(map(str, range(gpu_count)))
                print(f"ğŸš€ å°†ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ: {self.device}")
        else:
            print("âŒ æœªæ£€æµ‹åˆ°å¯ç”¨GPU")
            self.device = 'cpu'
            print("ğŸŒ å°†ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")
        
        print()
        return self.device
    
    def prepare_dataset(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®é›†"""
        if not self.args.prepare_data:
            print("â© è·³è¿‡æ•°æ®å‡†å¤‡æ­¥éª¤")
            return True
            
        print("=" * 50)
        print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
        print("=" * 50)
        
        source_path = Path(self.args.source_dir)
        output_path = Path(self.args.data_dir)
        
        if not source_path.exists():
            print(f"âŒ æºæ•°æ®ç›®å½•ä¸å­˜åœ¨: {source_path}")
            return False
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        train_img_dir = output_path / 'images' / 'train'
        val_img_dir = output_path / 'images' / 'val'
        train_label_dir = output_path / 'labels' / 'train'
        val_label_dir = output_path / 'labels' / 'val'
        
        for dir_path in [train_img_dir, val_img_dir, train_label_dir, val_label_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_dir = source_path / 'images'
        label_dir = source_path / 'labels'
        
        if not image_dir.exists() or not label_dir.exists():
            print(f"âŒ æºç›®å½•ç»“æ„ä¸æ­£ç¡®ï¼Œéœ€è¦åŒ…å« images/ å’Œ labels/ æ–‡ä»¶å¤¹")
            return False
        
        image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp']
        image_files = []
        for ext in image_extensions:
            image_files.extend(list(image_dir.glob(ext)))
        
        image_files = sorted(image_files)
        print(f"ğŸ“· æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
        
        if len(image_files) == 0:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
            return False
        
        # éšæœºæ‰“ä¹±
        random.seed(self.args.seed)
        random.shuffle(image_files)
        
        # åˆ’åˆ†æ•°æ®é›†
        split_idx = int(len(image_files) * self.args.train_split)
        train_images = image_files[:split_idx]
        val_images = image_files[split_idx:]
        
        print(f"ğŸ“ˆ è®­ç»ƒé›†: {len(train_images)} å¼ å›¾åƒ")
        print(f"ğŸ“‰ éªŒè¯é›†: {len(val_images)} å¼ å›¾åƒ")
        
        # å¤åˆ¶æ–‡ä»¶
        def copy_files(file_list, img_target, label_target, dataset_type):
            print(f"ğŸ“‹ å¤åˆ¶{dataset_type}...")
            for img_path in file_list:
                # å¤åˆ¶å›¾åƒ
                shutil.copy2(img_path, img_target / img_path.name)
                
                # å¤åˆ¶æ ‡æ³¨
                label_name = img_path.stem + '.txt'
                label_path = label_dir / label_name
                if label_path.exists():
                    shutil.copy2(label_path, label_target / label_name)
                else:
                    print(f"âš ï¸  ç¼ºå°‘æ ‡æ³¨æ–‡ä»¶: {label_name}")
        
        copy_files(train_images, train_img_dir, train_label_dir, "è®­ç»ƒé›†")
        copy_files(val_images, val_img_dir, val_label_dir, "éªŒè¯é›†")
        
        # è¯»å–ç±»åˆ«ä¿¡æ¯
        classes_file = source_path / 'classes.txt'
        if classes_file.exists():
            with open(classes_file, 'r', encoding='utf-8') as f:
                classes = [line.strip() for line in f if line.strip()]
        else:
            print("âš ï¸  æœªæ‰¾åˆ°classes.txtï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«")
            classes = ['object']
        
        # åˆ›å»ºdata.yamlé…ç½®æ–‡ä»¶
        yaml_content = f"""# YOLOæ•°æ®é›†é…ç½®æ–‡ä»¶
# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

path: {output_path.absolute().as_posix()}  # æ•°æ®é›†æ ¹ç›®å½•
train: images/train  # è®­ç»ƒå›¾åƒç›¸å¯¹è·¯å¾„
val: images/val      # éªŒè¯å›¾åƒç›¸å¯¹è·¯å¾„

# ç±»åˆ«é…ç½®
nc: {len(classes)}  # ç±»åˆ«æ•°é‡
names: {classes}  # ç±»åˆ«åç§°åˆ—è¡¨
"""
        
        yaml_path = output_path / 'data.yaml'
        with open(yaml_path, 'w', encoding='utf-8') as f:
            f.write(yaml_content)
        
        print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_path}")
        print(f"ğŸ“„ é…ç½®æ–‡ä»¶: {yaml_path}")
        print(f"ğŸ·ï¸  ç±»åˆ«æ•°é‡: {len(classes)}")
        print(f"ğŸ·ï¸  ç±»åˆ«åç§°: {classes}")
        print()
        
        return True
    
    def setup_model_output_dir(self):
        """è®¾ç½®æ¨¡å‹è¾“å‡ºç›®å½•ï¼Œæ”¯æŒè‡ªå®šä¹‰è·¯å¾„"""
        base_dir = Path(self.args.model_output_dir)
        
        if self.args.use_timestamp:
            # ä½¿ç”¨æ—¶é—´æˆ³é¿å…è¦†ç›–
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            exp_name = f"{self.args.experiment_name}_{timestamp}"
            self.model_output_dir = base_dir / exp_name
        else:
            # ç›´æ¥ä½¿ç”¨å®éªŒåç§°æˆ–æŒ‡å®šçš„å®Œæ•´è·¯å¾„
            if base_dir.is_absolute() and self.args.experiment_name in str(base_dir):
                # å¦‚æœmodel_output_dirå·²ç»åŒ…å«äº†å®Œæ•´è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
                self.model_output_dir = base_dir
            else:
                # å¦åˆ™åœ¨base_dirä¸‹åˆ›å»ºexperiment_nameç›®å½•
                self.model_output_dir = base_dir / self.args.experiment_name
        
        self.model_output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ æ¨¡å‹å°†ä¿å­˜åˆ°: {self.model_output_dir}")
        return str(self.model_output_dir)
    
    def train_model(self):
        """è®­ç»ƒYOLOæ¨¡å‹"""
        print("=" * 50)
        print("ğŸš€ å¼€å§‹è®­ç»ƒYOLOæ¨¡å‹...")
        print("=" * 50)
        
        # æ£€æŸ¥æ•°æ®é…ç½®æ–‡ä»¶
        data_yaml = Path(self.args.data_yaml)
        if not data_yaml.exists():
            print(f"âŒ æ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml}")
            return None
        
        # è®¾ç½®æ¨¡å‹è¾“å‡ºç›®å½•
        project_dir = self.setup_model_output_dir()
        
        # åŠ è½½æ¨¡å‹
        if self.args.resume_from:
            model = YOLO(self.args.resume_from)
            print(f"ğŸ“‚ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {self.args.resume_from}")
        else:
            model = YOLO(self.args.model_size)
            print(f"ğŸ¤– ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹: {self.args.model_size}")
        
        print(f"âš™ï¸  è®­ç»ƒå‚æ•°:")
        print(f"   - è®­ç»ƒè½®æ•°: {self.args.epochs}")
        print(f"   - æ‰¹æ¬¡å¤§å°: {self.args.batch_size}")
        print(f"   - å›¾åƒå¤§å°: {self.args.image_size}")
        print(f"   - è®¾å¤‡: {self.device}")
        print(f"   - å·¥ä½œçº¿ç¨‹: {self.args.workers}")
        print()
        
        # å¼€å§‹è®­ç»ƒ
        results = model.train(
            data=str(data_yaml),
            epochs=self.args.epochs,
            imgsz=self.args.image_size,
            batch=self.args.batch_size,
            name='train',
            project=project_dir,
            device=self.device,
            workers=self.args.workers,
            patience=self.args.patience,
            save=True,
            save_period=self.args.save_period if self.args.save_period > 0 else -1,
            cache=self.args.cache,
            optimizer=self.args.optimizer,
            verbose=True,
            seed=self.args.seed,
            lr0=self.args.learning_rate,
            lrf=self.args.lr_final_ratio,
            momentum=0.937,
            weight_decay=0.0005,
            warmup_epochs=3.0,
            cos_lr=self.args.cosine_lr,
            val=True,
        )
        
        print("\n" + "=" * 50)
        print("âœ… è®­ç»ƒå®Œæˆ!")
        print("=" * 50)
        
        # è®­ç»ƒç»“æœè·¯å¾„
        train_dir = Path(project_dir) / 'train'
        weights_dir = train_dir / 'weights'
        
        best_model = weights_dir / 'best.pt'
        last_model = weights_dir / 'last.pt'
        
        if best_model.exists():
            print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model}")
        if last_model.exists():
            print(f"ğŸ“± æœ€ç»ˆæ¨¡å‹: {last_model}")
        
        return best_model if best_model.exists() else last_model
    
    def export_to_onnx(self, model_path):
        """å¯¼å‡ºæ¨¡å‹ä¸ºONNXæ ¼å¼"""
        if not self.args.export_onnx:
            print("â© è·³è¿‡ONNXå¯¼å‡º")
            return
        
        if not model_path or not Path(model_path).exists():
            print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•å¯¼å‡ºONNX")
            return
        
        print("=" * 50)
        print("ğŸ“¦ å¯¼å‡ºONNXæ¨¡å‹...")
        print("=" * 50)
        
        try:
            model = YOLO(str(model_path))
            
            print(f"ğŸ“„ åŠ è½½æ¨¡å‹: {model_path}")
            print(f"ğŸ”§ å¯¼å‡ºé…ç½®: å›¾åƒå¤§å°={self.args.image_size}, ç®€åŒ–=True")
            
            # å¯¼å‡ºONNX
            onnx_path = model.export(
                format='onnx',
                imgsz=self.args.image_size,
                simplify=True,
                dynamic=False,
                opset=12
            )
            
            # å¤åˆ¶åˆ°Modelç›®å½•
            onnx_filename = f"{self.args.experiment_name}_model.onnx"
            target_onnx = self.model_output_dir / onnx_filename
            shutil.copy2(onnx_path, target_onnx)
            
            print(f"âœ… ONNXæ¨¡å‹å·²å¯¼å‡º: {target_onnx}")
            print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
            print(f"   - è¾“å…¥å°ºå¯¸: {self.args.image_size}x{self.args.image_size}")
            print(f"   - æ ¼å¼: ONNX (opset=12)")
            
        except Exception as e:
            print(f"âŒ ONNXå¯¼å‡ºå¤±è´¥: {e}")
    
    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        print("\n" + "ğŸ¯" * 20)
        print("YOLOè®­ç»ƒä¸€ä½“åŒ–è„šæœ¬å¯åŠ¨")
        print("ğŸ¯" * 20)
        
        # 1. æ£€æµ‹GPU/CPU
        self.check_gpu()
        
        # 2. å‡†å¤‡æ•°æ®é›†
        if not self.prepare_dataset():
            print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œç»ˆæ­¢è®­ç»ƒ")
            return False
        
        # 3. è®­ç»ƒæ¨¡å‹
        model_path = self.train_model()
        if not model_path:
            print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
            return False
        
        # 4. å¯¼å‡ºONNX
        self.export_to_onnx(model_path)
        
        print("\n" + "ğŸ‰" * 20)
        print("ğŸ‰ è®­ç»ƒæµç¨‹å…¨éƒ¨å®Œæˆ! ğŸ‰")
        print("ğŸ‰" * 20)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.model_output_dir}")
        
        return True


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='YOLOè®­ç»ƒä¸€ä½“åŒ–è„šæœ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºç¡€è®­ç»ƒ
  python StartTrain.py --source-dir project-6-at-2025-10-29-15-54-bac1d4f3 --epochs 100
  
  # å®Œæ•´é…ç½®è®­ç»ƒ
  python StartTrain.py \\
    --source-dir project-6-at-2025-10-29-15-54-bac1d4f3 \\
    --data-dir datasets \\
    --epochs 200 \\
    --batch-size 32 \\
    --model-size yolo11s.pt \\
    --export-onnx \\
    --experiment-name checkpoint_detection
        """
    )
    
    # æ•°æ®ç›¸å…³å‚æ•°
    data_group = parser.add_argument_group('æ•°æ®é…ç½®')
    data_group.add_argument('--source-dir', type=str, 
                           default='project-6-at-2025-10-29-15-54-bac1d4f3',
                           help='åŸå§‹æ•°æ®é›†ç›®å½•')
    data_group.add_argument('--data-dir', type=str, default='datasets',
                           help='å¤„ç†åçš„æ•°æ®é›†è¾“å‡ºç›®å½•')
    data_group.add_argument('--data-yaml', type=str, default='datasets/data.yaml',
                           help='YOLOæ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„')
    data_group.add_argument('--prepare-data', action='store_true', default=True,
                           help='æ˜¯å¦æ‰§è¡Œæ•°æ®å‡†å¤‡æ­¥éª¤')
    data_group.add_argument('--no-prepare-data', dest='prepare_data', action='store_false',
                           help='è·³è¿‡æ•°æ®å‡†å¤‡æ­¥éª¤')
    data_group.add_argument('--train-split', type=float, default=0.8,
                           help='è®­ç»ƒé›†æ¯”ä¾‹ (0.0-1.0)')
    
    # è®­ç»ƒç›¸å…³å‚æ•°
    train_group = parser.add_argument_group('è®­ç»ƒé…ç½®')
    train_group.add_argument('--epochs', type=int, default=100,
                            help='è®­ç»ƒè½®æ•°')
    train_group.add_argument('--batch-size', type=int, default=16,
                            help='æ‰¹æ¬¡å¤§å°')
    train_group.add_argument('--image-size', type=int, default=640,
                            help='è¾“å…¥å›¾åƒå¤§å°')
    train_group.add_argument('--model-size', type=str, default='yolo11n.pt',
                            choices=['yolo11n.pt', 'yolo11s.pt', 'yolo11m.pt', 'yolo11l.pt', 'yolo11x.pt'],
                            help='é¢„è®­ç»ƒæ¨¡å‹å¤§å°')
    train_group.add_argument('--resume-from', type=str, default=None,
                            help='ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒçš„æ¨¡å‹è·¯å¾„')
    train_group.add_argument('--workers', type=int, default=8,
                            help='æ•°æ®åŠ è½½å·¥ä½œçº¿ç¨‹æ•°')
    train_group.add_argument('--patience', type=int, default=50,
                            help='æ—©åœè€å¿ƒå€¼(epochs)')
    train_group.add_argument('--save-period', type=int, default=-1,
                            help='æ¯Nä¸ªepochä¿å­˜æ£€æŸ¥ç‚¹ (-1ä»…ä¿å­˜æœ€å)')
    
    # ä¼˜åŒ–å™¨ç›¸å…³å‚æ•°
    optim_group = parser.add_argument_group('ä¼˜åŒ–å™¨é…ç½®')
    optim_group.add_argument('--optimizer', type=str, default='auto',
                            choices=['SGD', 'Adam', 'AdamW', 'auto'],
                            help='ä¼˜åŒ–å™¨é€‰æ‹©')
    optim_group.add_argument('--learning-rate', type=float, default=0.01,
                            help='åˆå§‹å­¦ä¹ ç‡')
    optim_group.add_argument('--lr-final-ratio', type=float, default=0.01,
                            help='æœ€ç»ˆå­¦ä¹ ç‡æ¯”ç‡')
    optim_group.add_argument('--cosine-lr', action='store_true',
                            help='ä½¿ç”¨ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦å™¨')
    optim_group.add_argument('--cache', type=str, default='',
                            choices=['', 'ram', 'disk'],
                            help='å›¾åƒç¼“å­˜æ–¹å¼')
    
    # è®¾å¤‡ç›¸å…³å‚æ•°
    device_group = parser.add_argument_group('è®¾å¤‡é…ç½®')
    device_group.add_argument('--force-cpu', action='store_true',
                             help='å¼ºåˆ¶ä½¿ç”¨CPUè®­ç»ƒ')
    
    # è¾“å‡ºç›¸å…³å‚æ•°
    output_group = parser.add_argument_group('è¾“å‡ºé…ç½®')
    output_group.add_argument('--model-output-dir', type=str, default='Model',
                             help='æ¨¡å‹è¾“å‡ºæ ¹ç›®å½•')
    output_group.add_argument('--experiment-name', type=str, default='yolo_train',
                             help='å®éªŒåç§°')
    output_group.add_argument('--export-onnx', action='store_true',
                             help='è®­ç»ƒå®Œæˆåå¯¼å‡ºONNXæ ¼å¼')
    
    # å…¶ä»–å‚æ•°
    misc_group = parser.add_argument_group('å…¶ä»–é…ç½®')
    misc_group.add_argument('--seed', type=int, default=42,
                           help='éšæœºç§å­')
    misc_group.add_argument('--verbose', action='store_true', default=True,
                           help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶è¿è¡Œ
    trainer = YOLOTrainer(args)
    
    try:
        success = trainer.run()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâŒ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def start_train(
    source_dir='project-6-at-2025-10-29-15-54-bac1d4f3',
    epochs=100,
    batch_size=16,
    model_size='yolo11n.pt',
    experiment_name='yolo_train',
    export_onnx=False,
    force_cpu=False,
    data_dir='datasets',
    image_size=640,
    learning_rate=0.01,
    workers=8,
    resume_from=None,
    model_output_dir='Model',
    use_timestamp=True,
    prepare_data=True,
    **kwargs
):
    """
    ç›´æ¥è°ƒç”¨è®­ç»ƒå‡½æ•°ï¼ŒåƒC#é‚£æ ·ä¼ å‚
    
    Args:
        source_dir (str): åŸå§‹æ•°æ®é›†ç›®å½•
        epochs (int): è®­ç»ƒè½®æ•°
        batch_size (int): æ‰¹æ¬¡å¤§å°
        model_size (str): æ¨¡å‹å¤§å° ('yolo11n.pt', 'yolo11s.pt', 'yolo11m.pt', 'yolo11l.pt', 'yolo11x.pt')
        experiment_name (str): å®éªŒåç§°
        export_onnx (bool): æ˜¯å¦å¯¼å‡ºONNXæ ¼å¼
        force_cpu (bool): æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨CPU
        data_dir (str): å¤„ç†åæ•°æ®é›†è¾“å‡ºç›®å½•
        image_size (int): è¾“å…¥å›¾åƒå¤§å°
        learning_rate (float): å­¦ä¹ ç‡
        workers (int): å·¥ä½œçº¿ç¨‹æ•°
        resume_from (str): ä»æŒ‡å®šæ¨¡å‹/æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒçš„è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä»å¤´å¼€å§‹è®­ç»ƒ
        model_output_dir (str): æ¨¡å‹è¾“å‡ºæ ¹ç›®å½•ï¼Œå¯ä»¥æŒ‡å®šå®Œæ•´è·¯å¾„
        use_timestamp (bool): æ˜¯å¦åœ¨è¾“å‡ºç›®å½•åä¸­æ·»åŠ æ—¶é—´æˆ³ï¼ŒFalseåˆ™ç›´æ¥ä½¿ç”¨experiment_name
        prepare_data (bool): æ˜¯å¦æ‰§è¡Œæ•°æ®å‡†å¤‡æ­¥éª¤ï¼ŒFalseåˆ™è·³è¿‡æ•°æ®è½¬æ¢
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        dict: åŒ…å«è®­ç»ƒç»“æœå’Œæ¨¡å‹è·¯å¾„çš„å­—å…¸
            {
                'success': bool,  # è®­ç»ƒæ˜¯å¦æˆåŠŸ
                'model_dir': str,  # æ¨¡å‹è¾“å‡ºç›®å½•
                'best_model': str,  # æœ€ä½³æ¨¡å‹è·¯å¾„
                'last_model': str,  # æœ€ç»ˆæ¨¡å‹è·¯å¾„
                'onnx_model': str  # ONNXæ¨¡å‹è·¯å¾„(å¦‚æœå¯¼å‡º)
            }
        
    Example:
        # åŸºç¡€è°ƒç”¨
        success = start_train(
            source_dir='project-6-at-2025-10-29-15-54-bac1d4f3',
            epochs=50,
            batch_size=16
        )
        
        # å®Œæ•´è°ƒç”¨
        success = start_train(
            source_dir='my_dataset',
            epochs=200,
            batch_size=32,
            model_size='yolo11s.pt',
            experiment_name='my_model',
            export_onnx=True,
            learning_rate=0.01
        )
        
        # ä»å·²æœ‰æ¨¡å‹ç»§ç»­è®­ç»ƒ
        success = start_train(
            source_dir='my_dataset',
            epochs=100,
            batch_size=16,
            experiment_name='fine_tuned_model',
            resume_from='Model/previous_model_20241113_120000/train/weights/best.pt'
        )
        
        # æŒ‡å®šä¿å­˜åœ°å€
        success = start_train(
            source_dir='my_dataset',
            epochs=100,
            experiment_name='custom_model',
            model_output_dir='D:/MyModels/CustomPath',  # è‡ªå®šä¹‰ä¿å­˜è·¯å¾„
            use_timestamp=False  # ä¸ä½¿ç”¨æ—¶é—´æˆ³
        )
    """
    
    # åˆ›å»ºå‚æ•°å¯¹è±¡
    class Args:
        def __init__(self):
            # æ•°æ®é…ç½®
            self.source_dir = source_dir
            self.data_dir = data_dir
            self.data_yaml = f'{data_dir}/data.yaml'
            self.prepare_data = prepare_data
            self.train_split = kwargs.get('train_split', 0.8)
            
            # è®­ç»ƒé…ç½®
            self.epochs = epochs
            self.batch_size = batch_size
            self.image_size = image_size
            self.model_size = model_size
            self.resume_from = resume_from
            self.workers = workers
            self.patience = kwargs.get('patience', 50)
            self.save_period = kwargs.get('save_period', -1)
            
            # ä¼˜åŒ–å™¨é…ç½®
            self.optimizer = kwargs.get('optimizer', 'auto')
            self.learning_rate = learning_rate
            self.lr_final_ratio = kwargs.get('lr_final_ratio', 0.01)
            self.cosine_lr = kwargs.get('cosine_lr', False)
            self.cache = kwargs.get('cache', '')
            
            # è®¾å¤‡é…ç½®
            self.force_cpu = force_cpu
            
            # è¾“å‡ºé…ç½®
            self.model_output_dir = model_output_dir
            self.experiment_name = experiment_name
            self.export_onnx = export_onnx
            self.use_timestamp = use_timestamp
            
            # å…¶ä»–é…ç½®
            self.seed = kwargs.get('seed', 42)
            self.verbose = kwargs.get('verbose', True)
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶è¿è¡Œ
    args = Args()
    trainer = YOLOTrainer(args)
    
    try:
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ - å®éªŒåç§°: {experiment_name}")
        print(f"ğŸ“‚ æ•°æ®æº: {source_dir}")
        print(f"âš™ï¸  é…ç½®: {epochs}è½®æ¬¡, æ‰¹æ¬¡å¤§å°{batch_size}")
        
        if resume_from:
            print(f"ğŸ“‚ ä»æ¨¡å‹æ¢å¤: {resume_from}")
        else:
            print(f"ğŸ¤– ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹: {model_size}")
            
        print(f"ğŸ’¾ è¾“å‡º: Model/{experiment_name}_[æ—¶é—´æˆ³]/")
        if export_onnx:
            print(f"ğŸ“¦ å°†å¯¼å‡ºONNXæ ¼å¼")
        print()
        
        success = trainer.run()
        
        # æ”¶é›†æ¨¡å‹è·¯å¾„ä¿¡æ¯
        result = {
            'success': success,
            'model_dir': str(trainer.model_output_dir) if trainer.model_output_dir else None,
            'best_model': None,
            'last_model': None,
            'onnx_model': None
        }
        
        if success and trainer.model_output_dir:
            # æ„å»ºæ¨¡å‹è·¯å¾„
            train_dir = Path(trainer.model_output_dir) / 'train'
            weights_dir = train_dir / 'weights'
            
            best_model = weights_dir / 'best.pt'
            last_model = weights_dir / 'last.pt'
            
            if best_model.exists():
                result['best_model'] = str(best_model)
            if last_model.exists():
                result['last_model'] = str(last_model)
            
            # ONNXæ¨¡å‹è·¯å¾„
            if export_onnx:
                onnx_filename = f"{experiment_name}_model.onnx"
                onnx_path = Path(trainer.model_output_dir) / onnx_filename
                if onnx_path.exists():
                    result['onnx_model'] = str(onnx_path)
            
            print(f"\nâœ… è®­ç»ƒæˆåŠŸå®Œæˆ!")
            print(f"ğŸ“ æ¨¡å‹ç›®å½•: {result['model_dir']}")
            if result['best_model']:
                print(f"ğŸ† æœ€ä½³æ¨¡å‹: {result['best_model']}")
            if result['last_model']:
                print(f"ğŸ“± æœ€ç»ˆæ¨¡å‹: {result['last_model']}")
            if result['onnx_model']:
                print(f"ğŸ“¦ ONNXæ¨¡å‹: {result['onnx_model']}")
        else:
            print(f"\nâŒ è®­ç»ƒå¤±è´¥")
            
        return result
        
    except KeyboardInterrupt:
        print("\nâŒ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        return {'success': False, 'model_dir': None, 'best_model': None, 'last_model': None, 'onnx_model': None}
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return {'success': False, 'model_dir': None, 'best_model': None, 'last_model': None, 'onnx_model': None}


if __name__ == '__main__':
    main()
